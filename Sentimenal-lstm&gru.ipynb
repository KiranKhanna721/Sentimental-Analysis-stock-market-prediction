{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7afb130",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import matplotlib.pyplot as plt\n",
    "from urllib.request import urlopen\n",
    "from urllib.request import Request\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import numpy as np\n",
    "from textblob import TextBlob\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "import nltk\n",
    "import string\n",
    "from nltk import ngrams\n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.stem import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb0e4086",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b82ae272",
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_clean(review): \n",
    "    # changing to lower case\n",
    "    lower = review.str.lower()\n",
    "    \n",
    "    # Replacing the repeating pattern of &#039;\n",
    "    pattern_remove = lower.str.replace(\"&#039;\", \"\")\n",
    "    \n",
    "    # Removing all the special Characters\n",
    "    special_remove = pattern_remove.str.replace(r'[^\\w\\d\\s]',' ')\n",
    "    \n",
    "    # Removing all the non ASCII characters\n",
    "    ascii_remove = special_remove.str.replace(r'[^\\x00-\\x7F]+',' ')\n",
    "    \n",
    "    # Removing the leading and trailing Whitespaces\n",
    "    whitespace_remove = ascii_remove.str.replace(r'^\\s+|\\s+?$','')\n",
    "    \n",
    "    # Replacing multiple Spaces with Single Space\n",
    "    multiw_remove = whitespace_remove.str.replace(r'\\s+',' ')\n",
    "    \n",
    "    # Replacing Two or more dots with one\n",
    "    dataframe = multiw_remove.str.replace(r'\\.{2,}', ' ')\n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ddb26c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Text'] = review_clean(df['Headline'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d38e3481",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "df['Text'] = df['Text'].apply(lambda x: ' '.join(word for word in x.split() if word not in stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f978716e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Snow_ball = SnowballStemmer(\"english\")\n",
    "df['Text'] = df['Text'].apply(lambda x: \" \".join(Snow_ball.stem(word) for word in x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07fca768",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Headline</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>TCS</td>\n",
       "      <td>May-03-22</td>\n",
       "      <td>04:05PM</td>\n",
       "      <td>The Container Store Group, Inc. Announces Four...</td>\n",
       "      <td>contain store group inc announc fourth quarter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>TCS</td>\n",
       "      <td>Apr-12-22</td>\n",
       "      <td>12:12PM</td>\n",
       "      <td>The Container Store Group, Inc.'s (NYSE:TCS) S...</td>\n",
       "      <td>contain store group inc nyse tcs stock slide f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>TCS</td>\n",
       "      <td>Apr-11-22</td>\n",
       "      <td>08:18AM</td>\n",
       "      <td>Tata Consultancy Earnings Trail Estimates Afte...</td>\n",
       "      <td>tata consult earn trail estim labor crunch boo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>TCS</td>\n",
       "      <td>Apr-05-22</td>\n",
       "      <td>02:45AM</td>\n",
       "      <td>Payments Canada Partners with TCS to Evolve Pa...</td>\n",
       "      <td>payment canada partner tcs evolv payment rtr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>TCS</td>\n",
       "      <td>Mar-31-22</td>\n",
       "      <td>08:30AM</td>\n",
       "      <td>The Container Store Introduces New Loyalty Pro...</td>\n",
       "      <td>contain store introduc new loyalti program</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 Ticker       Date     Time  \\\n",
       "0           0    TCS  May-03-22  04:05PM   \n",
       "1           1    TCS  Apr-12-22  12:12PM   \n",
       "2           2    TCS  Apr-11-22  08:18AM   \n",
       "3           3    TCS  Apr-05-22  02:45AM   \n",
       "4           4    TCS  Mar-31-22  08:30AM   \n",
       "\n",
       "                                            Headline  \\\n",
       "0  The Container Store Group, Inc. Announces Four...   \n",
       "1  The Container Store Group, Inc.'s (NYSE:TCS) S...   \n",
       "2  Tata Consultancy Earnings Trail Estimates Afte...   \n",
       "3  Payments Canada Partners with TCS to Evolve Pa...   \n",
       "4  The Container Store Introduces New Loyalty Pro...   \n",
       "\n",
       "                                                Text  \n",
       "0  contain store group inc announc fourth quarter...  \n",
       "1  contain store group inc nyse tcs stock slide f...  \n",
       "2  tata consult earn trail estim labor crunch boo...  \n",
       "3       payment canada partner tcs evolv payment rtr  \n",
       "4         contain store introduc new loyalti program  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1759b6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment(review):\n",
    "    # Sentiment polarity of the reviews\n",
    "    pol = []\n",
    "    for i in review:\n",
    "        analysis = TextBlob(i)\n",
    "        pol.append(analysis.sentiment.polarity)\n",
    "    return pol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2eb314cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment'] = sentiment(df['Headline'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c061ad8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment_clean'] = sentiment(df['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cbe9aba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Headline</th>\n",
       "      <th>Text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>TCS</td>\n",
       "      <td>May-03-22</td>\n",
       "      <td>04:05PM</td>\n",
       "      <td>The Container Store Group, Inc. Announces Four...</td>\n",
       "      <td>contain store group inc announc fourth quarter...</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>0.175000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>TCS</td>\n",
       "      <td>Apr-12-22</td>\n",
       "      <td>12:12PM</td>\n",
       "      <td>The Container Store Group, Inc.'s (NYSE:TCS) S...</td>\n",
       "      <td>contain store group inc nyse tcs stock slide f...</td>\n",
       "      <td>-0.033333</td>\n",
       "      <td>-0.033333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>TCS</td>\n",
       "      <td>Apr-11-22</td>\n",
       "      <td>08:18AM</td>\n",
       "      <td>Tata Consultancy Earnings Trail Estimates Afte...</td>\n",
       "      <td>tata consult earn trail estim labor crunch boo...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>TCS</td>\n",
       "      <td>Apr-05-22</td>\n",
       "      <td>02:45AM</td>\n",
       "      <td>Payments Canada Partners with TCS to Evolve Pa...</td>\n",
       "      <td>payment canada partner tcs evolv payment rtr</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>TCS</td>\n",
       "      <td>Mar-31-22</td>\n",
       "      <td>08:30AM</td>\n",
       "      <td>The Container Store Introduces New Loyalty Pro...</td>\n",
       "      <td>contain store introduc new loyalti program</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.136364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 Ticker       Date     Time  \\\n",
       "0           0    TCS  May-03-22  04:05PM   \n",
       "1           1    TCS  Apr-12-22  12:12PM   \n",
       "2           2    TCS  Apr-11-22  08:18AM   \n",
       "3           3    TCS  Apr-05-22  02:45AM   \n",
       "4           4    TCS  Mar-31-22  08:30AM   \n",
       "\n",
       "                                            Headline  \\\n",
       "0  The Container Store Group, Inc. Announces Four...   \n",
       "1  The Container Store Group, Inc.'s (NYSE:TCS) S...   \n",
       "2  Tata Consultancy Earnings Trail Estimates Afte...   \n",
       "3  Payments Canada Partners with TCS to Evolve Pa...   \n",
       "4  The Container Store Introduces New Loyalty Pro...   \n",
       "\n",
       "                                                Text  sentiment  \\\n",
       "0  contain store group inc announc fourth quarter...   0.175000   \n",
       "1  contain store group inc nyse tcs stock slide f...  -0.033333   \n",
       "2  tata consult earn trail estim labor crunch boo...   0.000000   \n",
       "3       payment canada partner tcs evolv payment rtr   0.000000   \n",
       "4         contain store introduc new loyalti program   0.136364   \n",
       "\n",
       "   sentiment_clean  \n",
       "0         0.175000  \n",
       "1        -0.033333  \n",
       "2         0.000000  \n",
       "3         0.000000  \n",
       "4         0.136364  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f97c7433",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df['sentiment_clean'] >= 0.05), 'real_sentiment'] = 1\n",
    "df.loc[(df['sentiment_clean'] < 0.05), 'real_sentiment'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7bfe733d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Headline</th>\n",
       "      <th>Text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_clean</th>\n",
       "      <th>real_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>TCS</td>\n",
       "      <td>May-03-22</td>\n",
       "      <td>04:05PM</td>\n",
       "      <td>The Container Store Group, Inc. Announces Four...</td>\n",
       "      <td>contain store group inc announc fourth quarter...</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>TCS</td>\n",
       "      <td>Apr-12-22</td>\n",
       "      <td>12:12PM</td>\n",
       "      <td>The Container Store Group, Inc.'s (NYSE:TCS) S...</td>\n",
       "      <td>contain store group inc nyse tcs stock slide f...</td>\n",
       "      <td>-0.033333</td>\n",
       "      <td>-0.033333</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>TCS</td>\n",
       "      <td>Apr-11-22</td>\n",
       "      <td>08:18AM</td>\n",
       "      <td>Tata Consultancy Earnings Trail Estimates Afte...</td>\n",
       "      <td>tata consult earn trail estim labor crunch boo...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>TCS</td>\n",
       "      <td>Apr-05-22</td>\n",
       "      <td>02:45AM</td>\n",
       "      <td>Payments Canada Partners with TCS to Evolve Pa...</td>\n",
       "      <td>payment canada partner tcs evolv payment rtr</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>TCS</td>\n",
       "      <td>Mar-31-22</td>\n",
       "      <td>08:30AM</td>\n",
       "      <td>The Container Store Introduces New Loyalty Pro...</td>\n",
       "      <td>contain store introduc new loyalti program</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 Ticker       Date     Time  \\\n",
       "0           0    TCS  May-03-22  04:05PM   \n",
       "1           1    TCS  Apr-12-22  12:12PM   \n",
       "2           2    TCS  Apr-11-22  08:18AM   \n",
       "3           3    TCS  Apr-05-22  02:45AM   \n",
       "4           4    TCS  Mar-31-22  08:30AM   \n",
       "\n",
       "                                            Headline  \\\n",
       "0  The Container Store Group, Inc. Announces Four...   \n",
       "1  The Container Store Group, Inc.'s (NYSE:TCS) S...   \n",
       "2  Tata Consultancy Earnings Trail Estimates Afte...   \n",
       "3  Payments Canada Partners with TCS to Evolve Pa...   \n",
       "4  The Container Store Introduces New Loyalty Pro...   \n",
       "\n",
       "                                                Text  sentiment  \\\n",
       "0  contain store group inc announc fourth quarter...   0.175000   \n",
       "1  contain store group inc nyse tcs stock slide f...  -0.033333   \n",
       "2  tata consult earn trail estim labor crunch boo...   0.000000   \n",
       "3       payment canada partner tcs evolv payment rtr   0.000000   \n",
       "4         contain store introduc new loyalti program   0.136364   \n",
       "\n",
       "   sentiment_clean  real_sentiment  \n",
       "0         0.175000             1.0  \n",
       "1        -0.033333             0.0  \n",
       "2         0.000000             0.0  \n",
       "3         0.000000             0.0  \n",
       "4         0.136364             1.0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a4179208",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D ,GRU, Dropout\n",
    "from sklearn.model_selection import train_test_split \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a02d2c58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X tokenized data =  [[  0   0   0   0   0   2   1   3   4   8  31  11  38  12  13   7  14  17]\n",
      " [  0   0   0   0   0   2   1   3   4   9   5   6 126 127  62  39  23  63]\n",
      " [  0   0   0   0   0   0   0   0   0  64  65   7 128  24 129 130 131  66]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  40 132  32   5 133  40 134]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   2   1 135  15 136 137]]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(df['Text'].values)\n",
    "X = tokenizer.texts_to_sequences(df['Text'].values)\n",
    "X = pad_sequences(X)\n",
    "print(\"X tokenized data = \", X[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4e7550eb",
   "metadata": {},
   "outputs": [],
   "source": [
    " y = pd.get_dummies(df['real_sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d1a53f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0921fe9d",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5aa3defd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 18, 256)           1280000   \n",
      "                                                                 \n",
      " spatial_dropout1d_1 (Spatia  (None, 18, 256)          0         \n",
      " lDropout1D)                                                     \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 18, 256)           525312    \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 256)               525312    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 514       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,331,138\n",
      "Trainable params: 2,331,138\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lstm = Sequential()\n",
    "lstm.add(Embedding(5000, 256, input_length=X.shape[1]))\n",
    "lstm.add(SpatialDropout1D(0.4))\n",
    "lstm.add(LSTM(256, return_sequences=True, dropout=0.3, recurrent_dropout=0.2))\n",
    "lstm.add(LSTM(256, dropout=0.3, recurrent_dropout=0.2))\n",
    "lstm.add(Dense(2, activation='softmax'))\n",
    "lstm.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ec378388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 3.5729e-05 - accuracy: 1.0000\n",
      "Epoch 2/30\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 7.1802e-05 - accuracy: 1.0000\n",
      "Epoch 3/30\n",
      "3/3 [==============================] - 0s 162ms/step - loss: 1.5739e-04 - accuracy: 1.0000\n",
      "Epoch 4/30\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 2.0599e-04 - accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 7.3735e-05 - accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "3/3 [==============================] - 0s 160ms/step - loss: 2.3740e-05 - accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 2.4890e-05 - accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 5.6120e-05 - accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 3.7358e-05 - accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "3/3 [==============================] - 0s 163ms/step - loss: 3.1879e-05 - accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "3/3 [==============================] - 1s 171ms/step - loss: 6.8347e-05 - accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 4.2646e-05 - accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 2.5458e-05 - accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 2.2739e-05 - accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "3/3 [==============================] - 1s 177ms/step - loss: 1.0431e-04 - accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 2.3490e-05 - accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 1.7525e-05 - accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 1.5001e-05 - accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 8.7743e-05 - accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 3.5629e-05 - accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 7.2350e-05 - accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "3/3 [==============================] - 1s 185ms/step - loss: 7.0841e-05 - accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 6.6940e-05 - accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 3.1934e-05 - accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 1.8101e-05 - accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 1.5897e-05 - accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 1.0627e-05 - accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 1.1174e-05 - accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 5.3091e-05 - accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 1.5807e-05 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21dbf5454c0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size=32\n",
    "lstm.fit(X_train, y_train, epochs = 30,batch_size=batch_size, verbose = 'auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "191974de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 444ms/step - loss: 1.7759 - accuracy: 0.7500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.7759454250335693, 0.75]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9980ebf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_3 (Embedding)     (None, 18, 256)           1280000   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 18, 256)           0         \n",
      "                                                                 \n",
      " gru (GRU)                   (None, 18, 256)           394752    \n",
      "                                                                 \n",
      " gru_1 (GRU)                 (None, 256)               394752    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 514       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,070,018\n",
      "Trainable params: 2,070,018\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gru = Sequential()\n",
    "gru.add(Embedding(5000, 256, input_length=X.shape[1]))\n",
    "gru.add(Dropout(0.3))\n",
    "gru.add(GRU(256, return_sequences=True, dropout=0.3, recurrent_dropout=0.2))\n",
    "gru.add(GRU(256, dropout=0.3, recurrent_dropout=0.2))\n",
    "gru.add(Dense(2, activation='softmax'))\n",
    "gru.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "gru.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "73a6555a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "3/3 [==============================] - 4s 127ms/step - loss: 0.6808 - accuracy: 0.5750\n",
      "Epoch 2/30\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.6160 - accuracy: 0.6750\n",
      "Epoch 3/30\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.6098 - accuracy: 0.6750\n",
      "Epoch 4/30\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.5601 - accuracy: 0.6750\n",
      "Epoch 5/30\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.5012 - accuracy: 0.7375\n",
      "Epoch 6/30\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.4007 - accuracy: 0.8625\n",
      "Epoch 7/30\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.2614 - accuracy: 0.9375\n",
      "Epoch 8/30\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.1355 - accuracy: 0.9250\n",
      "Epoch 9/30\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0901 - accuracy: 0.9750\n",
      "Epoch 10/30\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0331 - accuracy: 0.9750\n",
      "Epoch 11/30\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0588 - accuracy: 0.9875\n",
      "Epoch 12/30\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0327 - accuracy: 0.9875\n",
      "Epoch 13/30\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0109 - accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0210 - accuracy: 0.9875\n",
      "Epoch 16/30\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0046 - accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0126 - accuracy: 0.9875\n",
      "Epoch 18/30\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0098 - accuracy: 0.9875\n",
      "Epoch 19/30\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 6.5805e-04 - accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 7.5468e-04 - accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 3.1302e-04 - accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 1.4032e-04 - accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 2.6071e-04 - accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 1.3040e-04 - accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 1.5485e-04 - accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 1.8312e-04 - accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 1.5112e-04 - accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 8.5742e-05 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21dbf7677c0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size=32\n",
    "gru.fit(X_train, y_train, epochs = 30,batch_size=batch_size, verbose = 'auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a664e32a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 2.2905 - accuracy: 0.7000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.2905304431915283, 0.699999988079071]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gru.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "60173f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = gru.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "60adf5e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average negative sentiment score = 0.6489429473876953\n",
      "Average positive sentiment score = 0.3510570526123047\n"
     ]
    }
   ],
   "source": [
    "avg_neg = np.mean([prediction[0] for prediction in predictions])\n",
    "avg_pos = np.mean([prediction[1] for prediction in predictions])\n",
    "print(f\"Average negative sentiment score = {avg_neg}\\nAverage positive sentiment score = {avg_pos}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0272a771",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"tata Consultancy Earnings Trail Estimates After Labor Crunch Boosts Costs \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "32edbfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(text)\n",
    "X1 = tokenizer.texts_to_sequences(text)\n",
    "X1 = pad_sequences(X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c8a92e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = gru.predict(X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "754a2644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average negative sentiment score = 0.5716809034347534\n",
      "Average positive sentiment score = 0.42831921577453613\n"
     ]
    }
   ],
   "source": [
    "avg_neg = np.mean([prediction[0] for prediction in predictions])\n",
    "avg_pos = np.mean([prediction[1] for prediction in predictions])\n",
    "print(f\"Average negative sentiment score = {avg_neg}\\nAverage positive sentiment score = {avg_pos}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3915b616",
   "metadata": {},
   "outputs": [],
   "source": [
    "gru.save('gru.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc714cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
